{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7a0dce6-aa72-4140-b432-66de70c2ac7e",
   "metadata": {},
   "source": [
    "Downloading the Iowa Elections Files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62035307-f6f9-422b-a89a-457c4999e4fb",
   "metadata": {},
   "source": [
    "1: Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1624381c-39e8-423d-9da0-77b26d338dce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROOT: /Users/sophiafazzina/Documents/STAT3255/team_b\n",
      "2016 download folder: /Users/sophiafazzina/Documents/STAT3255/team_b/data/raw/2016\n",
      "2018 download folder: /Users/sophiafazzina/Documents/STAT3255/team_b/data/raw/2018\n",
      "2020 download folder: /Users/sophiafazzina/Documents/STAT3255/team_b/data/raw/2020\n",
      "output folder: /Users/sophiafazzina/Documents/STAT3255/team_b/output\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "\n",
    "ROOT = Path.home() / \"Documents\" / \"STAT3255\" / \"team_b\"\n",
    "\n",
    "RAW_DIR = ROOT / \"data\" / \"raw\"\n",
    "OUT_DIR = ROOT / \"output\"\n",
    "\n",
    "YEAR_DIR = {\n",
    "    2016: RAW_DIR / \"2016\",\n",
    "    2018: RAW_DIR / \"2018\",\n",
    "    2020: RAW_DIR / \"2020\",\n",
    "}\n",
    "\n",
    "# create folders\n",
    "for p in list(YEAR_DIR.values()) + [OUT_DIR]:\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"ROOT:\", ROOT.resolve())\n",
    "for y, p in YEAR_DIR.items():\n",
    "    print(f\"{y} download folder:\", p.resolve())\n",
    "print(\"output folder:\", OUT_DIR.resolve())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1e5f88-dec5-49cf-a494-cedcc40c388a",
   "metadata": {},
   "source": [
    "2: Driver Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f70e6fea-f233-4a3d-b3d8-9de2177d4744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now downloading into: /Users/sophiafazzina/Documents/STAT3255/team_b/data/raw/2016\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "def make_driver(download_dir: Path, headless: bool = False):\n",
    "    download_dir = download_dir.resolve()\n",
    "\n",
    "    options = webdriver.ChromeOptions()\n",
    "\n",
    "    \n",
    "    prefs = {\n",
    "        \"download.default_directory\": str(download_dir),\n",
    "        \"download.prompt_for_download\": False,\n",
    "        \"download.directory_upgrade\": True,\n",
    "        \"safebrowsing.enabled\": True,\n",
    "    }\n",
    "    options.add_experimental_option(\"prefs\", prefs)\n",
    "\n",
    "    \n",
    "    if headless:\n",
    "        options.add_argument(\"--headless=new\")\n",
    "\n",
    "    driver = webdriver.Chrome(\n",
    "        service=Service(ChromeDriverManager().install()),\n",
    "        options=options\n",
    "    )\n",
    "    return driver\n",
    "\n",
    "def set_download_dir(driver, download_dir: Path):\n",
    "    \"\"\"Change Chrome's download folder after the driver is already running.\"\"\"\n",
    "    download_dir = download_dir.resolve()\n",
    "    driver.execute_cdp_cmd(\n",
    "        \"Page.setDownloadBehavior\",\n",
    "        {\"behavior\": \"allow\", \"downloadPath\": str(download_dir)}\n",
    "    )\n",
    "    print(\"Now downloading into:\", download_dir)\n",
    "\n",
    "\n",
    "driver = make_driver(YEAR_DIR[2016], headless=False)\n",
    "set_download_dir(driver, YEAR_DIR[2016])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b762af-f6a4-4830-ba3e-8826da663ae9",
   "metadata": {},
   "source": [
    "3: Collect Excel Links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b63a71ec-fda9-4145-b748-17138d44634c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016 links: 101 example: https://sos.iowa.gov/elections/pdf/precinctresults/2016general/adair.xlsx\n",
      "2018 links: 101 example: https://sos.iowa.gov/elections/pdf/precinctresults/2018general/adair.xls\n",
      "2020 links: 101 example: https://sos.iowa.gov/elections/pdf/precinctresults/2020general/adair.xlsx\n"
     ]
    }
   ],
   "source": [
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "YEAR_PAGE = {\n",
    "    2016: \"https://sos.iowa.gov/precinct-results-county-2016-general\",\n",
    "    2018: \"https://sos.iowa.gov/precinct-results-county-2018-general\",\n",
    "    2020: \"https://sos.iowa.gov/precinct-results-county-2020-general\",\n",
    "}\n",
    "\n",
    "def get_excel_links(driver, year: int, wait_s: float = 2.0):\n",
    "    \"\"\"\n",
    "    Open the year page and return a de-duplicated list of .xls/.xlsx links.\n",
    "    \"\"\"\n",
    "    driver.get(YEAR_PAGE[year])\n",
    "    time.sleep(wait_s)  \n",
    "\n",
    "    anchors = driver.find_elements(By.TAG_NAME, \"a\")\n",
    "    links = []\n",
    "    for a in anchors:\n",
    "        href = a.get_attribute(\"href\")\n",
    "        if not href:\n",
    "            continue\n",
    "        h = href.lower()\n",
    "        if h.endswith(\".xls\") or h.endswith(\".xlsx\"):\n",
    "            links.append(href)\n",
    "\n",
    "    \n",
    "    links = list(dict.fromkeys(links))\n",
    "    return links\n",
    "\n",
    "# quick test\n",
    "for y in [2016, 2018, 2020]:\n",
    "    links = get_excel_links(driver, y)\n",
    "    print(y, \"links:\", len(links), \"example:\", links[0] if links else \"NONE\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d5b220-4209-4a0b-9413-0fd4ef9fc87f",
   "metadata": {},
   "source": [
    "4: Filter Links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa0497d9-a8fc-41ce-891e-09f2a464f7aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now downloading into: /Users/sophiafazzina/Documents/STAT3255/team_b/data/raw/2016\n",
      "2016: filtered to 99 excel links\n",
      "2016: folder now has 99 .xls/.xlsx files (example: adair.xlsx)\n",
      "Now downloading into: /Users/sophiafazzina/Documents/STAT3255/team_b/data/raw/2018\n",
      "2018: filtered to 99 excel links\n",
      "2018: folder now has 98 .xls/.xlsx files (example: adair.xls)\n",
      "Now downloading into: /Users/sophiafazzina/Documents/STAT3255/team_b/data/raw/2020\n",
      "2020: filtered to 99 excel links\n",
      "2020: processed 2/99 (downloaded=1, skipped=1)\n",
      "2020: processed 30/99 (downloaded=5, skipped=25)\n",
      "2020: folder now has 98 .xls/.xlsx files (example: adair.xlsx)\n"
     ]
    }
   ],
   "source": [
    "from urllib.parse import urlparse\n",
    "\n",
    "def filename_from_url(url: str) -> str:\n",
    "    return urlparse(url).path.split(\"/\")[-1]\n",
    "\n",
    "def looks_like_county_file(url: str, year: int) -> bool:\n",
    "    \"\"\"\n",
    "    Keep links that look like Iowa county files.\n",
    "    Typical pattern includes /precinctresults/<year>general/<county>.xls(x)\n",
    "    \"\"\"\n",
    "    u = url.lower()\n",
    "    if not (u.endswith(\".xls\") or u.endswith(\".xlsx\")):\n",
    "        return False\n",
    "    if str(year) not in u or \"general\" not in u:\n",
    "        return False\n",
    "    if \"precinctresults\" not in u:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def download_year(driver, year: int, sleep_s: float = 0.6):\n",
    "    year_dir = YEAR_DIR[year]\n",
    "    set_download_dir(driver, year_dir)\n",
    "\n",
    "    links = get_excel_links(driver, year)\n",
    "    links = [u for u in links if looks_like_county_file(u, year)]\n",
    "    links = list(dict.fromkeys(links))  \n",
    "\n",
    "    print(f\"{year}: filtered to {len(links)} excel links\")\n",
    "\n",
    "    triggered = 0\n",
    "    skipped = 0\n",
    "\n",
    "    for i, url in enumerate(links, start=1):\n",
    "        fname = filename_from_url(url)\n",
    "        out_path = year_dir / fname\n",
    "\n",
    "        if out_path.exists():\n",
    "            skipped += 1\n",
    "            continue\n",
    "\n",
    "        driver.get(url)  # triggers download\n",
    "        triggered += 1\n",
    "\n",
    "        if i <= 5 or i % 10 == 0 or i == len(links):\n",
    "            print(f\"{year}: processed {i}/{len(links)} (downloaded={triggered}, skipped={skipped})\")\n",
    "\n",
    "        time.sleep(sleep_s)\n",
    "\n",
    "    # give downloads a moment to finish writing\n",
    "    time.sleep(2)\n",
    "\n",
    "    # count whatâ€™s actually there\n",
    "    files = sorted(list(year_dir.glob(\"*.xls*\")))\n",
    "    print(f\"{year}: folder now has {len(files)} .xls/.xlsx files (example: {files[0].name if files else 'NONE'})\")\n",
    "    return files\n",
    "\n",
    "# run year-by-year\n",
    "files_2016 = download_year(driver, 2016)\n",
    "files_2018 = download_year(driver, 2018)\n",
    "files_2020 = download_year(driver, 2020)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503db765-032c-48ac-a61a-b2d96b2ef0d3",
   "metadata": {},
   "source": [
    "5: Convert to CSV (one per year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1f9f962-d341-4379-ab26-1115f6d21a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def read_excel_smart(path):\n",
    "    try:\n",
    "        return pd.read_excel(path, engine=\"openpyxl\")\n",
    "    except Exception:\n",
    "        return pd.read_excel(path, engine=\"xlrd\")\n",
    "\n",
    "def build_year_csv(year: int, out_csv):\n",
    "    files = sorted(YEAR_DIR[year].glob(\"*.xls*\"))\n",
    "    if not files:\n",
    "        raise RuntimeError(f\"No Excel files found for {year} in {YEAR_DIR[year]}\")\n",
    "\n",
    "    frames = []\n",
    "    bad = []\n",
    "\n",
    "    for f in files:\n",
    "        try:\n",
    "            df = read_excel_smart(f)\n",
    "\n",
    "            if df is None or df.shape[0] == 0:\n",
    "                bad.append((f.name, \"EMPTY_SHEET\"))\n",
    "                continue\n",
    "\n",
    "            df.columns = [str(c) for c in df.columns]\n",
    "            df[\"source_file\"] = f.name\n",
    "            df[\"year\"] = year\n",
    "            frames.append(df)\n",
    "\n",
    "        except Exception as e:\n",
    "            bad.append((f.name, repr(e)))\n",
    "\n",
    "    if not frames:\n",
    "        raise RuntimeError(f\"All files failed for {year}. Example errors: {bad[:5]}\")\n",
    "\n",
    "    big = pd.concat(frames, ignore_index=True, sort=True)\n",
    "    out_csv = Path(out_csv)\n",
    "    out_csv.parent.mkdir(parents=True, exist_ok=True)\n",
    "    big.to_csv(out_csv, index=False)\n",
    "\n",
    "    print(f\"{year}: wrote {out_csv} with {len(big):,} rows from {len(frames)} files\")\n",
    "    if bad:\n",
    "        print(f\"{year}: {len(bad)} files skipped/failed (showing up to 15):\")\n",
    "        for name, err in bad[:15]:\n",
    "            print(\"  \", name, \"->\", err)\n",
    "\n",
    "    return big\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4073a088-c9c2-4d85-b3f0-94e4bc6770e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m26.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip -q install xlrd==2.0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cae9ab1-8eee-4edc-9036-a11b95e369c0",
   "metadata": {},
   "source": [
    "Run the pip install above and then restart the kernel. Then re run the other chunks to get the variables back. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "873aab57-9c3b-4713-97b6-73ee47c5552e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016: wrote /Users/sophiafazzina/Documents/STAT3255/team_b/output/iowa_precinct_returns_2016.csv with 51,975 rows from 99 files\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "csv_2016 = OUT_DIR / \"iowa_precinct_returns_2016.csv\"\n",
    "\n",
    "df2016 = build_year_csv(2016, csv_2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "663e25e8-ba60-4f4d-86cd-e81db2880a9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020: wrote /Users/sophiafazzina/Documents/STAT3255/team_b/output/iowa_precinct_returns_2020.csv with 4,343 rows from 98 files\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "csv_2020 = OUT_DIR / \"iowa_precinct_returns_2020.csv\"\n",
    "\n",
    "df2020 = build_year_csv(2020, csv_2020)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954ce92d-3585-4931-b544-179c2fc80345",
   "metadata": {},
   "source": [
    "Code to convert the 2018 files from xls to xlsx. I'm doing this so that the files will work with the same combination script that I used for 2016 and 2020."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a10a650-b5ca-4209-abc4-c50fe9b83baa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018 input files found: 98\n",
      "2018 converted to .xlsx: 98\n",
      "2018 failed: 0\n",
      "Converted folder: /Users/sophiafazzina/Documents/STAT3255/team_b/data/raw/2018_xlsx\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "Y2018_IN  = YEAR_DIR[2018]\n",
    "Y2018_OUT = RAW_DIR / \"2018_xlsx\"\n",
    "Y2018_OUT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def sniff_kind(p: Path) -> str:\n",
    "    head = p.read_bytes()[:4096]\n",
    "    if head.startswith(b\"PK\\x03\\x04\"):\n",
    "        return \"xlsx_zip\"\n",
    "    low = head.lower()\n",
    "    if b\"urn:schemas-microsoft-com:office:spreadsheet\" in low or b\"<workbook\" in low:\n",
    "        return \"spreadsheetml\"\n",
    "    if b\"<html\" in low or b\"<!doctype html\" in low:\n",
    "        return \"html\"\n",
    "    if head.startswith(b\"\\xD0\\xCF\\x11\\xE0\\xA1\\xB1\\x1A\\xE1\"):\n",
    "        return \"xls_binary\"\n",
    "    return \"unknown\"\n",
    "\n",
    "def read_spreadsheetml_to_df(p: Path) -> pd.DataFrame:\n",
    "   \n",
    "    raw = p.read_bytes()\n",
    "    text = raw.decode(\"utf-8\", errors=\"ignore\")\n",
    "\n",
    "    root = ET.fromstring(text)\n",
    "\n",
    "    def local(tag: str) -> str:\n",
    "        # '{namespace}Row' -> 'Row'\n",
    "        return tag.split(\"}\")[-1] if \"}\" in tag else tag\n",
    "\n",
    "    rows_out = []\n",
    "    for row in root.iter():\n",
    "        if local(row.tag) != \"Row\":\n",
    "            continue\n",
    "\n",
    "        row_vals = []\n",
    "        current_col = 1\n",
    "\n",
    "        for cell in row:\n",
    "            if local(cell.tag) != \"Cell\":\n",
    "                continue\n",
    "\n",
    "            \n",
    "            idx = None\n",
    "            for k, v in cell.attrib.items():\n",
    "                if k.endswith(\"Index\"):\n",
    "                    try:\n",
    "                        idx = int(v)\n",
    "                    except:\n",
    "                        idx = None\n",
    "                    break\n",
    "            if idx is not None and idx > current_col:\n",
    "                row_vals.extend([\"\"] * (idx - current_col))\n",
    "                current_col = idx\n",
    "\n",
    "            data_val = \"\"\n",
    "            for child in cell.iter():\n",
    "                if local(child.tag) == \"Data\" and child.text is not None:\n",
    "                    data_val = child.text\n",
    "                    break\n",
    "\n",
    "            row_vals.append(data_val)\n",
    "            current_col += 1\n",
    "\n",
    "        if any(str(x).strip() != \"\" for x in row_vals):\n",
    "            rows_out.append(row_vals)\n",
    "\n",
    "    if not rows_out:\n",
    "        raise ValueError(\"SpreadsheetML parse found 0 rows\")\n",
    "\n",
    "    \n",
    "    w = max(len(r) for r in rows_out)\n",
    "    rows_out = [r + [\"\"] * (w - len(r)) for r in rows_out]\n",
    "\n",
    "    header = [str(h).strip() if str(h).strip() else f\"col_{i}\" for i, h in enumerate(rows_out[0])]\n",
    "    data = rows_out[1:] if len(rows_out) > 1 else []\n",
    "    return pd.DataFrame(data, columns=header)\n",
    "\n",
    "def convert_one_2018_file(src: Path, out_dir: Path) -> Path:\n",
    "    kind = sniff_kind(src)\n",
    "    out_path = out_dir / (src.stem + \".xlsx\")\n",
    "\n",
    "    if out_path.exists():\n",
    "        return out_path\n",
    "\n",
    "    if kind == \"xlsx_zip\":\n",
    "        out_path.write_bytes(src.read_bytes())\n",
    "        return out_path\n",
    "\n",
    "    if kind == \"xls_binary\":\n",
    "        df = pd.read_excel(src, engine=\"xlrd\")\n",
    "\n",
    "    elif kind == \"spreadsheetml\":\n",
    "        try:\n",
    "            df = read_spreadsheetml_to_df(src)\n",
    "        except Exception:\n",
    "            \n",
    "            tables = pd.read_html(src, flavor=\"lxml\")\n",
    "            if not tables:\n",
    "                raise\n",
    "            df = tables[0]\n",
    "\n",
    "    elif kind == \"html\":\n",
    "        tables = pd.read_html(src, flavor=\"lxml\")\n",
    "        if not tables:\n",
    "            raise ValueError(\"No tables found in HTML file\")\n",
    "        df = tables[0]\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown file type for {src.name}\")\n",
    "\n",
    "    df.to_excel(out_path, index=False, engine=\"openpyxl\")\n",
    "    return out_path\n",
    "\n",
    "\n",
    "src_files = sorted(Y2018_IN.glob(\"*.xls*\"))\n",
    "print(\"2018 input files found:\", len(src_files))\n",
    "\n",
    "ok, bad = 0, []\n",
    "for f in src_files:\n",
    "    try:\n",
    "        convert_one_2018_file(f, Y2018_OUT)\n",
    "        ok += 1\n",
    "    except Exception as e:\n",
    "        bad.append((f.name, repr(e)))\n",
    "\n",
    "print(\"2018 converted to .xlsx:\", ok)\n",
    "print(\"2018 failed:\", len(bad))\n",
    "if bad:\n",
    "    print(\"Example failures (up to 10):\")\n",
    "    for name, err in bad[:10]:\n",
    "        print(\"  \", name, \"->\", err)\n",
    "\n",
    "print(\"Converted folder:\", Y2018_OUT.resolve())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c50d808e-cb40-4441-8741-8f5dec3730c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018: wrote /Users/sophiafazzina/Documents/STAT3255/team_b/output/iowa_precinct_returns_2018.csv with 67,320 rows from 98 files\n"
     ]
    }
   ],
   "source": [
    "YEAR_DIR[2018] = RAW_DIR / \"2018_xlsx\"\n",
    "\n",
    "csv_2018 = OUT_DIR / \"iowa_precinct_returns_2018.csv\"\n",
    "df2018 = build_year_csv(2018, csv_2018)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (stat3255)",
   "language": "python",
   "name": "stat3255"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
